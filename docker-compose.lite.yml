# =============================================================================
# EventFlow Platform - Lite Production Docker Compose
# Optimized for resource-constrained environments (e.g., micro instances)
# Removes observability stack and tunes JVM heap sizes
# =============================================================================
#
# Usage:
#   docker-compose -f docker-compose.lite.yml up --build
#   make up-lite
#
# =============================================================================

version: '3.8'

# =============================================================================
# Service Definitions
# =============================================================================
services:

  # ===========================================================================
  # Infrastructure Services
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Zookeeper - Kafka coordination service
  # ---------------------------------------------------------------------------
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: eventflow-zookeeper
    restart: unless-stopped
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      # Heap size tuning for micro instances
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=* -Xmx128M -Xms128M"
    healthcheck:
      test: ["CMD-SHELL", "echo srvr | nc localhost 2181 | grep Zookeeper"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log
    networks:
      - eventflow-network

  # ---------------------------------------------------------------------------
  # Kafka - Message broker
  # ---------------------------------------------------------------------------
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    container_name: eventflow-kafka
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9192:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9192
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      # Heap size tuning for micro instances
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms256M"
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:29092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 60s
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - eventflow-network

  # ---------------------------------------------------------------------------
  # Kafka Init - Create required topics
  # ---------------------------------------------------------------------------
  kafka-init:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka-init
    container_name: eventflow-kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/bash", "-c"]
    command: |
      "
      echo '=========================================='
      echo 'Creating Kafka topics...'
      echo '=========================================='

      # Wait for Kafka to be fully ready
      sleep 5

      # Create service-metrics topic
      kafka-topics --create --if-not-exists \
        --topic service-metrics \
        --bootstrap-server kafka:29092 \
        --partitions 3 \
        --replication-factor 1 \
        --config retention.ms=604800000 \
        --config cleanup.policy=delete

      # Create service-logs topic
      kafka-topics --create --if-not-exists \
        --topic service-logs \
        --bootstrap-server kafka:29092 \
        --partitions 3 \
        --replication-factor 1 \
        --config retention.ms=604800000 \
        --config cleanup.policy=delete

      # Create alerts topic
      kafka-topics --create --if-not-exists \
        --topic alerts \
        --bootstrap-server kafka:29092 \
        --partitions 3 \
        --replication-factor 1 \
        --config retention.ms=604800000 \
        --config cleanup.policy=delete

      # Create alerts-dlq (dead letter queue) topic
      kafka-topics --create --if-not-exists \
        --topic alerts-dlq \
        --bootstrap-server kafka:29092 \
        --partitions 1 \
        --replication-factor 1 \
        --config retention.ms=2592000000 \
        --config cleanup.policy=delete

      echo ''
      echo '=========================================='
      echo 'Topics created successfully:'
      echo '=========================================='
      kafka-topics --list --bootstrap-server kafka:29092
      echo ''
      echo 'Topic details:'
      kafka-topics --describe --bootstrap-server kafka:29092
      "
    networks:
      - eventflow-network

  # ---------------------------------------------------------------------------
  # Redis - Caching and data store
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7.2-alpine
    hostname: redis
    container_name: eventflow-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 0
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    volumes:
      - redis-data:/data
    networks:
      - eventflow-network

  # ===========================================================================
  # Application Services - Metric Generators
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Auth Service
  # ---------------------------------------------------------------------------
  auth:
    build:
      context: .
      dockerfile: services/auth/Dockerfile
    image: eventflow/auth:latest
    hostname: auth
    container_name: eventflow-auth
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    ports:
      - "8001:8080"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: auth
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_LOGS_TOPIC: service-logs
      LOG_LEVEL: info
      # Tracing disabled in lite mode
      JAEGER_ENDPOINT: ""
      OTEL_EXPORTER_OTLP_ENDPOINT: ""
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=auth"
      - "eventflow.type=generator"

  # ---------------------------------------------------------------------------
  # Orders Service
  # ---------------------------------------------------------------------------
  orders:
    build:
      context: .
      dockerfile: services/orders/Dockerfile
    image: eventflow/orders:latest
    hostname: orders
    container_name: eventflow-orders
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    ports:
      - "8002:8080"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: orders
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_LOGS_TOPIC: service-logs
      LOG_LEVEL: info
      JAEGER_ENDPOINT: ""
      OTEL_EXPORTER_OTLP_ENDPOINT: ""
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=orders"
      - "eventflow.type=generator"

  # ---------------------------------------------------------------------------
  # Payments Service
  # ---------------------------------------------------------------------------
  payments:
    build:
      context: .
      dockerfile: services/payments/Dockerfile
    image: eventflow/payments:latest
    hostname: payments
    container_name: eventflow-payments
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    ports:
      - "8003:8080"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: payments
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_LOGS_TOPIC: service-logs
      LOG_LEVEL: info
      JAEGER_ENDPOINT: ""
      OTEL_EXPORTER_OTLP_ENDPOINT: ""
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=payments"
      - "eventflow.type=generator"

  # ---------------------------------------------------------------------------
  # Notification Service
  # ---------------------------------------------------------------------------
  notification:
    build:
      context: .
      dockerfile: services/notification/Dockerfile
    image: eventflow/notification:latest
    hostname: notification
    container_name: eventflow-notification
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    ports:
      - "8004:8080"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: notification
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_LOGS_TOPIC: service-logs
      LOG_LEVEL: info
      JAEGER_ENDPOINT: ""
      OTEL_EXPORTER_OTLP_ENDPOINT: ""
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=notification"
      - "eventflow.type=generator"

  # ===========================================================================
  # Application Services - Core Platform
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Analyzer Service - Real-time anomaly detection
  # ---------------------------------------------------------------------------
  analyzer:
    build:
      context: .
      dockerfile: services/analyzer/Dockerfile
    image: eventflow/analyzer:latest
    hostname: analyzer
    container_name: eventflow-analyzer
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8005:8080"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: analyzer
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_ALERTS_TOPIC: alerts
      KAFKA_CONSUMER_GROUP: analyzer-group
      REDIS_ADDR: redis:6379
      REDIS_PASSWORD: ""
      REDIS_DB: "0"
      LOG_LEVEL: info
      JAEGER_ENDPOINT: ""
      OTEL_EXPORTER_OTLP_ENDPOINT: ""
      # Analyzer thresholds
      CPU_THRESHOLD: "80"
      MEMORY_THRESHOLD: "85"
      LATENCY_THRESHOLD: "500"
      ERROR_RATE_THRESHOLD: "5"
      ZSCORE_THRESHOLD: "3"
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=analyzer"
      - "eventflow.type=core"

  # ---------------------------------------------------------------------------
  # Alert Engine Service - Multi-channel alert dispatch
  # ---------------------------------------------------------------------------
  alert-engine:
    build:
      context: .
      dockerfile: services/alert-engine/Dockerfile
    image: eventflow/alert-engine:latest
    hostname: alert-engine
    container_name: eventflow-alert-engine
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8006:8080"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: alert-engine
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_ALERTS_TOPIC: alerts
      KAFKA_DLQ_TOPIC: alerts-dlq
      KAFKA_CONSUMER_GROUP: alert-engine-group
      REDIS_ADDR: redis:6379
      REDIS_PASSWORD: ""
      REDIS_DB: "1"
      LOG_LEVEL: info
      JAEGER_ENDPOINT: ""
      OTEL_EXPORTER_OTLP_ENDPOINT: ""
      # Alert dispatchers (configure as needed)
      SLACK_ENABLED: "false"
      SLACK_WEBHOOK_URL: ""
      EMAIL_ENABLED: "false"
      EMAIL_SMTP_HOST: ""
      EMAIL_SMTP_PORT: "587"
      EMAIL_FROM: ""
      WEBHOOK_ENABLED: "false"
      WEBHOOK_URLS: ""
      # Alert settings
      ALERT_SUPPRESSION_WINDOW: "300"
      MAX_RETRY_ATTEMPTS: "3"
      RETRY_BACKOFF_MS: "1000"
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=alert-engine"
      - "eventflow.type=core"

  # ---------------------------------------------------------------------------
  # UI Backend Service - REST API + WebSocket
  # ---------------------------------------------------------------------------
  ui-backend:
    build:
      context: .
      dockerfile: services/ui-backend/Dockerfile
    image: eventflow/ui-backend:latest
    hostname: ui-backend
    container_name: eventflow-ui-backend
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8007:8080"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: ui-backend
      HTTP_ADDR: ":8080"
      METRICS_ADDR: ":9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_ALERTS_TOPIC: alerts
      KAFKA_CONSUMER_GROUP: ui-backend-group
      REDIS_ADDR: redis:6379
      REDIS_PASSWORD: ""
      REDIS_DB: "2"
      # JWT Configuration (CHANGE IN PRODUCTION!)
      JWT_SECRET: "${JWT_SECRET:-eventflow-super-secret-key-change-me-in-production}"
      JWT_EXPIRATION: "24"
      # CORS Configuration
      ALLOWED_ORIGINS: "http://localhost:3001,http://localhost:3000,http://dashboard:3000"
      LOG_LEVEL: info
      JAEGER_ENDPOINT: ""
      OTEL_EXPORTER_OTLP_ENDPOINT: ""
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=ui-backend"
      - "eventflow.type=core"

  # ---------------------------------------------------------------------------
  # Dashboard - Next.js Frontend
  # ---------------------------------------------------------------------------
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
      args:
        NEXT_PUBLIC_API_URL: http://localhost:8007
        NEXT_PUBLIC_WS_URL: ws://localhost:8007/ws
    image: eventflow/dashboard:latest
    hostname: dashboard
    container_name: eventflow-dashboard
    restart: unless-stopped
    depends_on:
      ui-backend:
        condition: service_healthy
    ports:
      - "3001:3000"
    environment:
      NODE_ENV: production
      NEXT_PUBLIC_API_URL: http://localhost:8007
      NEXT_PUBLIC_WS_URL: ws://localhost:8007/ws
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=dashboard"
      - "eventflow.type=frontend"

# =============================================================================
# Networks
# =============================================================================
networks:
  eventflow-network:
    name: eventflow-network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16

# =============================================================================
# Volumes
# =============================================================================
volumes:
  zookeeper-data:
    name: eventflow-zookeeper-data
  zookeeper-log:
    name: eventflow-zookeeper-log
  kafka-data:
    name: eventflow-kafka-data
  redis-data:
    name: eventflow-redis-data
