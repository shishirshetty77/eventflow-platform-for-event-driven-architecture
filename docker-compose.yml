# =============================================================================
# EventFlow Platform - Production Docker Compose
# Complete microservices orchestration with all dependencies
# =============================================================================
#
# Usage:
#   docker-compose up --build        # Build and start all services
#   docker-compose up -d             # Start in detached mode
#   docker-compose logs -f           # Follow logs
#   docker-compose down              # Stop all services
#   docker-compose down -v           # Stop and remove volumes
#
# =============================================================================

version: '3.8'

# =============================================================================
# Service Definitions
# =============================================================================
services:

  # ===========================================================================
  # Infrastructure Services
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Zookeeper - Kafka coordination service
  # ---------------------------------------------------------------------------
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: eventflow-zookeeper
    restart: unless-stopped
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
    healthcheck:
      test: ["CMD-SHELL", "echo srvr | nc localhost 2181 | grep Zookeeper"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log
    networks:
      - eventflow-network

  # ---------------------------------------------------------------------------
  # Kafka - Message broker
  # ---------------------------------------------------------------------------
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    container_name: eventflow-kafka
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9192:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9192
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:29092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 60s
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - eventflow-network

  # ---------------------------------------------------------------------------
  # Kafka Init - Create required topics
  # ---------------------------------------------------------------------------
  kafka-init:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka-init
    container_name: eventflow-kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      bash -c "
      echo '==========================================';
      echo 'Creating Kafka topics...';
      echo '==========================================';
      sleep 5;
      kafka-topics --create --if-not-exists --topic service-metrics --bootstrap-server kafka:29092 --partitions 3 --replication-factor 1 --config retention.ms=604800000 --config cleanup.policy=delete;
      kafka-topics --create --if-not-exists --topic service-logs --bootstrap-server kafka:29092 --partitions 3 --replication-factor 1 --config retention.ms=604800000 --config cleanup.policy=delete;
      kafka-topics --create --if-not-exists --topic alerts --bootstrap-server kafka:29092 --partitions 3 --replication-factor 1 --config retention.ms=604800000 --config cleanup.policy=delete;
      kafka-topics --create --if-not-exists --topic alerts-dlq --bootstrap-server kafka:29092 --partitions 1 --replication-factor 1 --config retention.ms=2592000000 --config cleanup.policy=delete;
      echo '';
      echo '==========================================';
      echo 'Topics created successfully:';
      echo '==========================================';
      kafka-topics --list --bootstrap-server kafka:29092;
      echo '';
      echo 'Topic details:';
      kafka-topics --describe --bootstrap-server kafka:29092;
      "
    networks:
      - eventflow-network

  # ---------------------------------------------------------------------------
  # Redis - Caching and data store
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7.2-alpine
    hostname: redis
    container_name: eventflow-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 0
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    volumes:
      - redis-data:/data
    networks:
      - eventflow-network

  # ===========================================================================
  # Application Services - Metric Generators
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Auth Service
  # ---------------------------------------------------------------------------
  auth:
    build:
      context: .
      dockerfile: services/auth/Dockerfile
    image: eventflow/auth:latest
    hostname: auth
    container_name: eventflow-auth
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    ports:
      - "8001:8080"
      - "9101:9090"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: auth
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_LOGS_TOPIC: service-logs
      LOG_LEVEL: info
      JAEGER_ENDPOINT: http://jaeger:14268/api/traces
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=auth"
      - "eventflow.type=generator"

  # ---------------------------------------------------------------------------
  # Orders Service
  # ---------------------------------------------------------------------------
  orders:
    build:
      context: .
      dockerfile: services/orders/Dockerfile
    image: eventflow/orders:latest
    hostname: orders
    container_name: eventflow-orders
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    ports:
      - "8002:8080"
      - "9102:9090"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: orders
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_LOGS_TOPIC: service-logs
      LOG_LEVEL: info
      JAEGER_ENDPOINT: http://jaeger:14268/api/traces
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=orders"
      - "eventflow.type=generator"

  # ---------------------------------------------------------------------------
  # Payments Service
  # ---------------------------------------------------------------------------
  payments:
    build:
      context: .
      dockerfile: services/payments/Dockerfile
    image: eventflow/payments:latest
    hostname: payments
    container_name: eventflow-payments
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    ports:
      - "8003:8080"
      - "9103:9090"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: payments
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_LOGS_TOPIC: service-logs
      LOG_LEVEL: info
      JAEGER_ENDPOINT: http://jaeger:14268/api/traces
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=payments"
      - "eventflow.type=generator"

  # ---------------------------------------------------------------------------
  # Notification Service
  # ---------------------------------------------------------------------------
  notification:
    build:
      context: .
      dockerfile: services/notification/Dockerfile
    image: eventflow/notification:latest
    hostname: notification
    container_name: eventflow-notification
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    ports:
      - "8004:8080"
      - "9104:9090"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: notification
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_LOGS_TOPIC: service-logs
      LOG_LEVEL: info
      JAEGER_ENDPOINT: http://jaeger:14268/api/traces
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=notification"
      - "eventflow.type=generator"

  # ===========================================================================
  # Application Services - Core Platform
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Analyzer Service - Real-time anomaly detection
  # ---------------------------------------------------------------------------
  analyzer:
    build:
      context: .
      dockerfile: services/analyzer/Dockerfile
    image: eventflow/analyzer:latest
    hostname: analyzer
    container_name: eventflow-analyzer
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8005:8080"
      - "9105:9090"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: analyzer
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_ALERTS_TOPIC: alerts
      KAFKA_CONSUMER_GROUP: analyzer-group
      REDIS_ADDR: redis:6379
      REDIS_PASSWORD: ""
      REDIS_DB: "0"
      LOG_LEVEL: info
      JAEGER_ENDPOINT: http://jaeger:14268/api/traces
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
      # Analyzer thresholds
      CPU_THRESHOLD: "80"
      MEMORY_THRESHOLD: "85"
      LATENCY_THRESHOLD: "500"
      ERROR_RATE_THRESHOLD: "5"
      ZSCORE_THRESHOLD: "3"
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=analyzer"
      - "eventflow.type=core"

  # ---------------------------------------------------------------------------
  # Alert Engine Service - Multi-channel alert dispatch
  # ---------------------------------------------------------------------------
  alert-engine:
    build:
      context: .
      dockerfile: services/alert-engine/Dockerfile
    image: eventflow/alert-engine:latest
    hostname: alert-engine
    container_name: eventflow-alert-engine
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8006:8080"
      - "9106:9090"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: alert-engine
      HTTP_PORT: "8080"
      METRICS_PORT: "9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_ALERTS_TOPIC: alerts
      KAFKA_DLQ_TOPIC: alerts-dlq
      KAFKA_CONSUMER_GROUP: alert-engine-group
      REDIS_ADDR: redis:6379
      REDIS_PASSWORD: ""
      REDIS_DB: "1"
      LOG_LEVEL: info
      JAEGER_ENDPOINT: http://jaeger:14268/api/traces
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
      # Alert dispatchers (configure as needed)
      SLACK_ENABLED: "false"
      SLACK_WEBHOOK_URL: ""
      EMAIL_ENABLED: "false"
      EMAIL_SMTP_HOST: ""
      EMAIL_SMTP_PORT: "587"
      EMAIL_FROM: ""
      WEBHOOK_ENABLED: "false"
      WEBHOOK_URLS: ""
      # Alert settings
      ALERT_SUPPRESSION_WINDOW: "300"
      MAX_RETRY_ATTEMPTS: "3"
      RETRY_BACKOFF_MS: "1000"
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=alert-engine"
      - "eventflow.type=core"

  # ---------------------------------------------------------------------------
  # UI Backend Service - REST API + WebSocket
  # ---------------------------------------------------------------------------
  ui-backend:
    build:
      context: .
      dockerfile: services/ui-backend/Dockerfile
    image: eventflow/ui-backend:latest
    hostname: ui-backend
    container_name: eventflow-ui-backend
    restart: unless-stopped
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8007:8080"
      - "9107:9090"
    environment:
      ENVIRONMENT: production
      SERVICE_NAME: ui-backend
      HTTP_ADDR: ":8080"
      METRICS_ADDR: ":9090"
      KAFKA_BROKERS: kafka:29092
      KAFKA_METRICS_TOPIC: service-metrics
      KAFKA_ALERTS_TOPIC: alerts
      KAFKA_CONSUMER_GROUP: ui-backend-group
      REDIS_ADDR: redis:6379
      REDIS_PASSWORD: ""
      REDIS_DB: "0"
      # JWT Configuration (CHANGE IN PRODUCTION!)
      JWT_SECRET: "${JWT_SECRET:-eventflow-super-secret-key-change-me-in-production}"
      JWT_EXPIRATION: "24"
      # CORS Configuration
      ALLOWED_ORIGINS: "http://localhost:3001,http://localhost:3000,http://dashboard:3000"
      LOG_LEVEL: info
      JAEGER_ENDPOINT: http://jaeger:14268/api/traces
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=ui-backend"
      - "eventflow.type=core"

  # ---------------------------------------------------------------------------
  # Dashboard - Next.js Frontend
  # ---------------------------------------------------------------------------
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
      args:
        NEXT_PUBLIC_API_URL: http://localhost:8007
        NEXT_PUBLIC_WS_URL: ws://localhost:8007/ws
    image: eventflow/dashboard:latest
    hostname: dashboard
    container_name: eventflow-dashboard
    restart: unless-stopped
    depends_on:
      ui-backend:
        condition: service_healthy
    ports:
      - "3001:3000"
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "/dev/null", "http://127.0.0.1:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    environment:
      NODE_ENV: production
      NEXT_PUBLIC_API_URL: http://localhost:8007
      NEXT_PUBLIC_WS_URL: ws://localhost:8007/ws
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=dashboard"
      - "eventflow.type=frontend"

  # ===========================================================================
  # Observability Services
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Prometheus - Metrics collection
  # ---------------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:v2.47.0
    hostname: prometheus
    container_name: eventflow-prometheus
    restart: unless-stopped
    ports:
      - "9190:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    volumes:
      - ./deploy/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./deploy/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus-data:/prometheus
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=prometheus"
      - "eventflow.type=observability"

  # ---------------------------------------------------------------------------
  # Grafana - Metrics visualization
  # ---------------------------------------------------------------------------
  grafana:
    image: grafana/grafana:10.2.0
    hostname: grafana
    container_name: eventflow-grafana
    restart: unless-stopped
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: "${GRAFANA_PASSWORD:-admin}"
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: "http://localhost:3000"
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    volumes:
      - grafana-data:/var/lib/grafana
      - ./deploy/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./deploy/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=grafana"
      - "eventflow.type=observability"

  # ---------------------------------------------------------------------------
  # Jaeger - Distributed tracing
  # ---------------------------------------------------------------------------
  jaeger:
    image: jaegertracing/all-in-one:1.51
    hostname: jaeger
    container_name: eventflow-jaeger
    restart: unless-stopped
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14250:14250"
      - "14268:14268"
      - "14269:14269"
      - "4317:4317"
      - "4318:4318"
    environment:
      COLLECTOR_OTLP_ENABLED: "true"
      SPAN_STORAGE_TYPE: memory
      MEMORY_MAX_TRACES: 100000
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:14269/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=jaeger"
      - "eventflow.type=observability"

  # ---------------------------------------------------------------------------
  # Kafka UI - Kafka management interface
  # ---------------------------------------------------------------------------
  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.1
    hostname: kafka-ui
    container_name: eventflow-kafka-ui
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: eventflow
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      DYNAMIC_CONFIG_ENABLED: "true"
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=kafka-ui"
      - "eventflow.type=observability"

  # ---------------------------------------------------------------------------
  # Redis Commander - Redis management interface
  # ---------------------------------------------------------------------------
  redis-commander:
    image: rediscommander/redis-commander:latest
    hostname: redis-commander
    container_name: eventflow-redis-commander
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      REDIS_HOSTS: local:redis:6379
      HTTP_USER: admin
      HTTP_PASSWORD: "${REDIS_COMMANDER_PASSWORD:-admin}"
    networks:
      - eventflow-network
    labels:
      - "eventflow.service=redis-commander"
      - "eventflow.type=observability"

# =============================================================================
# Networks
# =============================================================================
networks:
  eventflow-network:
    name: eventflow-network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16

# =============================================================================
# Volumes
# =============================================================================
volumes:
  zookeeper-data:
    name: eventflow-zookeeper-data
  zookeeper-log:
    name: eventflow-zookeeper-log
  kafka-data:
    name: eventflow-kafka-data
  redis-data:
    name: eventflow-redis-data
  prometheus-data:
    name: eventflow-prometheus-data
  grafana-data:
    name: eventflow-grafana-data
  jaeger-data:
    name: eventflow-jaeger-data
